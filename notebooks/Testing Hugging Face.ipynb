{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd4d00e-8b9a-4b23-933d-30b64e9a453d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bcd4d00e-8b9a-4b23-933d-30b64e9a453d",
    "outputId": "30c9b62d-3ccc-4c6e-bdb8-98845d28be27",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ameezingwongstein/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-04-24 09:34:57.059408: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "from transformers import pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f0b7400",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7f0b7400",
    "outputId": "a0ad0fe6-5ff4-4ff1-eb3a-f4469da48c5f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ameezingwongstein/Library/Python/3.9/lib/python/site-packages/transformers/generation/utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'I HATE MY JOB. I HATE MY BUSINESS. I HATE MY LIFE. I DESERVE MY BUSINESS.\\n\\n'},\n",
       " {'generated_text': 'I HATE MY JOB FROM ME.\" In the same vein, this post is in no way addressing why I was wrong when I said that Obama'},\n",
       " {'generated_text': \"I HATE MY JOB AND DON'T TAKE A SINGLE STEP, OR YOU ARE DOING THOSE CRAZY POOR\"}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model = 'gpt2')\n",
    "generator(\"I HATE MY JOB\", max_length = 30, num_return_sequences=3)\n",
    "## [{'generated_text': \"Hello, I'm a language modeler. So while writing this, when I went out to meet my wife or come home she told me that my\"},"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e515e",
   "metadata": {
    "id": "540e515e"
   },
   "source": [
    "## Idea 1\n",
    "Train text generator on Amazon bad reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42856d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625,
     "referenced_widgets": [
      "d265e94caea24d5a98f9611881e0cd93",
      "fc11f13f935248ddb2c658747e2714bf",
      "2ff1031bdd444992845b2cb6a5ce3e5f",
      "6711d62b4f884571b95ea748c17a3298",
      "7eac96a60f474b38b3958a755072e33a",
      "2bea7f63b6f64633a4c93881d01a5994",
      "ee7ed57907b34da88f27f0370d325ce4",
      "df84ee6dc21d46d3a220542696f65cf0",
      "41146de71b99490585176f82c5b8aa0d",
      "edb6369fa1464d79805c380fc4fbf768",
      "0e4151c6cff940f1aef9ed8362f2af58"
     ]
    },
    "id": "e42856d1",
    "outputId": "e7f6f43f-9cec-4d0f-967e-75dd37fbbacc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "zsh:1: command not found: pip\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████████████| 60.0k/60.0k [00:00<00:00, 7.10MB/s]\n",
      "Found cached dataset amazon_us_reviews (/Users/ameezingwongstein/.cache/huggingface/datasets/amazon_us_reviews/Digital_Video_Games_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563)\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00, 14.79it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"amazon_us_reviews\", \"Digital_Video_Games_v1_00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d96aa56a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "d96aa56a",
    "outputId": "9aa40850-4159-4768-f343-72d8e519375d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>21269168</td>\n",
       "      <td>RSH1OZ87OYK92</td>\n",
       "      <td>B013PURRZW</td>\n",
       "      <td>603406193</td>\n",
       "      <td>Madden NFL 16 - Xbox One Digital Code</td>\n",
       "      <td>Digital_Video_Games</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A slight improvement from last year.</td>\n",
       "      <td>I keep buying madden every year hoping they ge...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>133437</td>\n",
       "      <td>R1WFOQ3N9BO65I</td>\n",
       "      <td>B00F4CEHNK</td>\n",
       "      <td>341969535</td>\n",
       "      <td>Xbox Live Gift Card</td>\n",
       "      <td>Digital_Video_Games</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>45765011</td>\n",
       "      <td>R3YOOS71KM5M9</td>\n",
       "      <td>B00DNHLFQA</td>\n",
       "      <td>951665344</td>\n",
       "      <td>Command &amp; Conquer The Ultimate Collection [Ins...</td>\n",
       "      <td>Digital_Video_Games</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hail to the great Yuri!</td>\n",
       "      <td>If you are prepping for the end of the world t...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>113118</td>\n",
       "      <td>R3R14UATT3OUFU</td>\n",
       "      <td>B004RMK5QG</td>\n",
       "      <td>395682204</td>\n",
       "      <td>Playstation Plus Subscription</td>\n",
       "      <td>Digital_Video_Games</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>22151364</td>\n",
       "      <td>RV2W9SGDNQA2C</td>\n",
       "      <td>B00G9BNLQE</td>\n",
       "      <td>640460561</td>\n",
       "      <td>Saints Row IV - Enter The Dominatrix [Online G...</td>\n",
       "      <td>Digital_Video_Games</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Awesome!</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace customer_id       review_id  product_id product_parent  \\\n",
       "0          US    21269168   RSH1OZ87OYK92  B013PURRZW      603406193   \n",
       "1          US      133437  R1WFOQ3N9BO65I  B00F4CEHNK      341969535   \n",
       "2          US    45765011   R3YOOS71KM5M9  B00DNHLFQA      951665344   \n",
       "3          US      113118  R3R14UATT3OUFU  B004RMK5QG      395682204   \n",
       "4          US    22151364   RV2W9SGDNQA2C  B00G9BNLQE      640460561   \n",
       "\n",
       "                                       product_title     product_category  \\\n",
       "0              Madden NFL 16 - Xbox One Digital Code  Digital_Video_Games   \n",
       "1                                Xbox Live Gift Card  Digital_Video_Games   \n",
       "2  Command & Conquer The Ultimate Collection [Ins...  Digital_Video_Games   \n",
       "3                      Playstation Plus Subscription  Digital_Video_Games   \n",
       "4  Saints Row IV - Enter The Dominatrix [Online G...  Digital_Video_Games   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes  vine  verified_purchase  \\\n",
       "0            2              2            3     0                  0   \n",
       "1            5              0            0     0                  1   \n",
       "2            5              0            0     0                  1   \n",
       "3            5              0            0     0                  1   \n",
       "4            5              0            0     0                  1   \n",
       "\n",
       "                        review_headline  \\\n",
       "0  A slight improvement from last year.   \n",
       "1                            Five Stars   \n",
       "2               Hail to the great Yuri!   \n",
       "3                            Five Stars   \n",
       "4                            Five Stars   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0  I keep buying madden every year hoping they ge...  2015-08-31  \n",
       "1                                            Awesome  2015-08-31  \n",
       "2  If you are prepping for the end of the world t...  2015-08-31  \n",
       "3                                            Perfect  2015-08-31  \n",
       "4                                           Awesome!  2015-08-31  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_df = pd.DataFrame.from_dict(dataset['train'])\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fc8099d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fc8099d",
    "outputId": "96c5d398-4799-4d60-a26d-a294790964bd",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24970"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_reviews = data_df.loc[data_df[\"star_rating\"] == 1]\n",
    "len(bad_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f39fabf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5f39fabf",
    "outputId": "e8efa180-6bbe-46f2-efa4-f5538a405b84",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    As has been written by so many others, I quick...\n",
       "14                Lames purchase I almost never made...\n",
       "24                                               Gross!\n",
       "26           Not the best graphics :(<br />Dissapointed\n",
       "30                                               Stolen\n",
       "Name: review_body, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_reviews[\"review_body\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "FILluNOqEwoq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FILluNOqEwoq",
    "outputId": "ccd0d349-752e-4543-e9a1-87b4d5ab146f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/_r4pmpsx6qjbvc93xxxb0lbm0000gn/T/ipykernel_49208/1791466554.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bad_reviews[\"message_len\"]=[len(i) for i in bad_reviews[\"review_body\"].values] # [0 for i in range(0,24970)]\n"
     ]
    }
   ],
   "source": [
    "bad_reviews[\"message_len\"]=[len(i) for i in bad_reviews[\"review_body\"].values] # [0 for i in range(0,24970)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18el3mHKFe0K",
   "metadata": {
    "id": "18el3mHKFe0K"
   },
   "outputs": [],
   "source": [
    "# dall=dall.mul(row.loc[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ArJhSLHFlso",
   "metadata": {
    "id": "2ArJhSLHFlso"
   },
   "outputs": [],
   "source": [
    "# [len(i) for i in bad_reviews[\"review_body\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "_sodZQxEF-Q6",
   "metadata": {
    "id": "_sodZQxEF-Q6"
   },
   "outputs": [],
   "source": [
    "bad_reviews_small=bad_reviews.loc[bad_reviews[\"message_len\"]<128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "PVwRVkbDG3er",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVwRVkbDG3er",
    "outputId": "a1eeb38c-82f5-449e-e4f4-fe2647181091"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7671, 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_reviews_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vGgvT7LoG86J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGgvT7LoG86J",
    "outputId": "acb479ee-1c21-4bcb-fdf4-49e67f7baeb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24970, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3YOg9zjBGqO1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3YOg9zjBGqO1",
    "outputId": "d5949cc6-d926-4dff-f839-fb62d91b5912"
   },
   "outputs": [],
   "source": [
    "# bad_reviews[\"message_len\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bhFkz3zRHAwk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bhFkz3zRHAwk",
    "outputId": "f1780f6e-102f-4240-ba71-a19f9f7a17ab"
   },
   "outputs": [],
   "source": [
    "# bad_reviews[\"message_len\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511a2a04",
   "metadata": {
    "id": "511a2a04"
   },
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcb23efd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcb23efd",
    "outputId": "08e0a687-6d45-4077-cdf7-be05c2d23308",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"
     ]
    }
   ],
   "source": [
    "# a little sentiment analysis\n",
    "model_name = \"finiteautomata/bertweet-base-sentiment-analysis\"\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accac968",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "accac968",
    "outputId": "754198c7-f223-4b3a-d07c-bddeefb61159",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'text-classification',\n",
       " 'model': RobertaForSequenceClassification(\n",
       "   (roberta): RobertaModel(\n",
       "     (embeddings): RobertaEmbeddings(\n",
       "       (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "       (position_embeddings): Embedding(130, 768, padding_idx=1)\n",
       "       (token_type_embeddings): Embedding(1, 768)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (encoder): RobertaEncoder(\n",
       "       (layer): ModuleList(\n",
       "         (0): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (1): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (2): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (3): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (4): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (5): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (6): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (7): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (8): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (9): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (10): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (11): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (classifier): RobertaClassificationHead(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "     (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "   )\n",
       " ),\n",
       " 'tokenizer': BertweetTokenizer(name_or_path='finiteautomata/bertweet-base-sentiment-analysis', vocab_size=64000, model_max_length=128, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}),\n",
       " 'feature_extractor': None,\n",
       " 'modelcard': None,\n",
       " 'framework': 'pt',\n",
       " 'device': device(type='cpu'),\n",
       " 'torch_dtype': None,\n",
       " 'binary_output': False,\n",
       " 'call_count': 0,\n",
       " '_batch_size': None,\n",
       " '_num_workers': None,\n",
       " '_preprocess_params': {},\n",
       " '_forward_params': {},\n",
       " '_postprocess_params': {}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bae1fda5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bae1fda5",
    "outputId": "7e2b4a6f-9670-4709-ef6c-026546e5012e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEG', 'score': 0.9216219782829285}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = bad_reviews_small[\"review_body\"].values[0]\n",
    "sentiment_pipeline(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12759d93",
   "metadata": {
    "id": "12759d93",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaner_data = None\n",
    "\n",
    "for index, bad_review in bad_reviews_small.iterrows():\n",
    "    sentiment = sentiment_pipeline(bad_review[\"review_body\"])[0]\n",
    "    if (sentiment[\"label\"] == \"POSITIVE\"):\n",
    "        cleaner_data = bad_reviews.drop(index=index, axis = 0)\n",
    "    elif sentiment[\"score\"] < 0.8:\n",
    "        cleaner_data = bad_reviews.drop(index=index, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae305d0c",
   "metadata": {
    "id": "ae305d0c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24969"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaner_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82737349",
   "metadata": {
    "id": "82737349",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaner_data.to_csv(\"cleaner_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4e28aa",
   "metadata": {
    "id": "fa4e28aa"
   },
   "source": [
    "# Retraining on top of transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d865ebeb",
   "metadata": {
    "id": "d865ebeb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fdbd117a",
   "metadata": {
    "id": "fdbd117a",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"As has been written by so many others, I quickly lost interest in this game. I am still playing Civ 4 and love it. It's a shame because I'm ready for an expanded version of Civ 4 and have waited for about a decade for a better version of it. Civ 5 was not an evolution but a total rewrite and it lost all that was good in Civ 4. I really hope that when Civ 6 comes out they use Civ 4 as the starting point and forget Civ 5 ever happened. Failing that there is a place in the market for a strategy game that involves building a civilisation.\",\n",
       " 'Lames purchase I almost never made...']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_reviews_array = cleaner_data[\"review_body\"].values.tolist()\n",
    "bad_reviews_array[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec7eb949",
   "metadata": {
    "id": "ec7eb949",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_bad_reviews = tokenizer(bad_reviews_array, \n",
    "                                  padding=True, truncation=True, max_length=512, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fae4e19e",
   "metadata": {
    "id": "fae4e19e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.tokenization_utils_base.BatchEncoding"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_bad_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "840baf54",
   "metadata": {
    "id": "840baf54",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TextGenerationPipeline' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 17\u001b[0m\n\u001b[1;32m      5\u001b[0m angry_comments \u001b[38;5;241m=\u001b[39m cleaner_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreview_body\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      7\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      8\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     num_train_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     logging_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./logs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenized_bad_reviews\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_mask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/trainer.py:445\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m tokenizer\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device:\n\u001b[0;32m--> 445\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/trainer.py:688\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[0;32m--> 688\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device)\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TextGenerationPipeline' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# \n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "angry_comments = cleaner_data[\"review_body\"].values\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=generator,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_bad_reviews,\n",
    "    data_collator=lambda data: {\"input_ids\": torch.stack([f[0] for f in data]), \n",
    "                                \"attention_mask\": torch.stack([f[1] for f in data]), \n",
    "                                \"labels\": torch.stack([f[0] for f in data])},\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b143d7c-89ae-4afe-a6e8-214cfe4ada67",
   "metadata": {
    "id": "0b143d7c-89ae-4afe-a6e8-214cfe4ada67",
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e4151c6cff940f1aef9ed8362f2af58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2bea7f63b6f64633a4c93881d01a5994": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ff1031bdd444992845b2cb6a5ce3e5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df84ee6dc21d46d3a220542696f65cf0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_41146de71b99490585176f82c5b8aa0d",
      "value": 1
     }
    },
    "41146de71b99490585176f82c5b8aa0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6711d62b4f884571b95ea748c17a3298": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edb6369fa1464d79805c380fc4fbf768",
      "placeholder": "​",
      "style": "IPY_MODEL_0e4151c6cff940f1aef9ed8362f2af58",
      "value": " 1/1 [00:00&lt;00:00, 26.20it/s]"
     }
    },
    "7eac96a60f474b38b3958a755072e33a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d265e94caea24d5a98f9611881e0cd93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc11f13f935248ddb2c658747e2714bf",
       "IPY_MODEL_2ff1031bdd444992845b2cb6a5ce3e5f",
       "IPY_MODEL_6711d62b4f884571b95ea748c17a3298"
      ],
      "layout": "IPY_MODEL_7eac96a60f474b38b3958a755072e33a"
     }
    },
    "df84ee6dc21d46d3a220542696f65cf0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edb6369fa1464d79805c380fc4fbf768": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee7ed57907b34da88f27f0370d325ce4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc11f13f935248ddb2c658747e2714bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2bea7f63b6f64633a4c93881d01a5994",
      "placeholder": "​",
      "style": "IPY_MODEL_ee7ed57907b34da88f27f0370d325ce4",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
