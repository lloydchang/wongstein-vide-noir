{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd4d00e-8b9a-4b23-933d-30b64e9a453d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bcd4d00e-8b9a-4b23-933d-30b64e9a453d",
    "outputId": "30c9b62d-3ccc-4c6e-bdb8-98845d28be27",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: pip\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ameezingwongstein/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-05-08 09:08:19.342052: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "from transformers import pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f0b7400",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7f0b7400",
    "outputId": "a0ad0fe6-5ff4-4ff1-eb3a-f4469da48c5f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ameezingwongstein/Library/Python/3.9/lib/python/site-packages/transformers/generation/utils.py:1186: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation)\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'I HATE MY JOB\" - \"THIS IS MY JOB\" - \"YOU NEED TO STOP SHITING ME OFF\" - \"I'},\n",
       " {'generated_text': 'I HATE MY JOB\" [18th July 2003]\\n\\nI\\'m on \\'Hard Rock Road\\' and in England I\\'m out in'},\n",
       " {'generated_text': \"I HATE MY JOB!!!!! [pause] [no. I never made a scene] OK then, I'll take a picture of you fucking\"}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model = 'gpt2')\n",
    "generator(\"I HATE MY JOB\", max_length = 30, num_return_sequences=3)\n",
    "## [{'generated_text': \"Hello, I'm a language modeler. So while writing this, when I went out to meet my wife or come home she told me that my\"},"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540e515e",
   "metadata": {
    "id": "540e515e"
   },
   "source": [
    "## Idea 1\n",
    "Train text generator on Amazon bad reviews\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e42856d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625,
     "referenced_widgets": [
      "d265e94caea24d5a98f9611881e0cd93",
      "fc11f13f935248ddb2c658747e2714bf",
      "2ff1031bdd444992845b2cb6a5ce3e5f",
      "6711d62b4f884571b95ea748c17a3298",
      "7eac96a60f474b38b3958a755072e33a",
      "2bea7f63b6f64633a4c93881d01a5994",
      "ee7ed57907b34da88f27f0370d325ce4",
      "df84ee6dc21d46d3a220542696f65cf0",
      "41146de71b99490585176f82c5b8aa0d",
      "edb6369fa1464d79805c380fc4fbf768",
      "0e4151c6cff940f1aef9ed8362f2af58"
     ]
    },
    "id": "e42856d1",
    "outputId": "e7f6f43f-9cec-4d0f-967e-75dd37fbbacc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "zsh:1: command not found: pip\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset amazon_us_reviews (/Users/ameezingwongstein/.cache/huggingface/datasets/amazon_us_reviews/Digital_Video_Games_v1_00/0.1.0/17b2481be59723469538adeb8fd0a68b0ba363bbbdd71090e72c325ee6c7e563)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  8.17it/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"amazon_us_reviews\", \"Digital_Video_Games_v1_00\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d96aa56a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "d96aa56a",
    "outputId": "9aa40850-4159-4768-f343-72d8e519375d",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>21269168</td>\n",
       "      <td>RSH1OZ87OYK92</td>\n",
       "      <td>B013PURRZW</td>\n",
       "      <td>603406193</td>\n",
       "      <td>Madden NFL 16 - Xbox One Digital Code</td>\n",
       "      <td>Digital_Video_Games</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A slight improvement from last year.</td>\n",
       "      <td>I keep buying madden every year hoping they ge...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>133437</td>\n",
       "      <td>R1WFOQ3N9BO65I</td>\n",
       "      <td>B00F4CEHNK</td>\n",
       "      <td>341969535</td>\n",
       "      <td>Xbox Live Gift Card</td>\n",
       "      <td>Digital_Video_Games</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>45765011</td>\n",
       "      <td>R3YOOS71KM5M9</td>\n",
       "      <td>B00DNHLFQA</td>\n",
       "      <td>951665344</td>\n",
       "      <td>Command &amp; Conquer The Ultimate Collection [Ins...</td>\n",
       "      <td>Digital_Video_Games</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Hail to the great Yuri!</td>\n",
       "      <td>If you are prepping for the end of the world t...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>113118</td>\n",
       "      <td>R3R14UATT3OUFU</td>\n",
       "      <td>B004RMK5QG</td>\n",
       "      <td>395682204</td>\n",
       "      <td>Playstation Plus Subscription</td>\n",
       "      <td>Digital_Video_Games</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>22151364</td>\n",
       "      <td>RV2W9SGDNQA2C</td>\n",
       "      <td>B00G9BNLQE</td>\n",
       "      <td>640460561</td>\n",
       "      <td>Saints Row IV - Enter The Dominatrix [Online G...</td>\n",
       "      <td>Digital_Video_Games</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>Awesome!</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace customer_id       review_id  product_id product_parent  \\\n",
       "0          US    21269168   RSH1OZ87OYK92  B013PURRZW      603406193   \n",
       "1          US      133437  R1WFOQ3N9BO65I  B00F4CEHNK      341969535   \n",
       "2          US    45765011   R3YOOS71KM5M9  B00DNHLFQA      951665344   \n",
       "3          US      113118  R3R14UATT3OUFU  B004RMK5QG      395682204   \n",
       "4          US    22151364   RV2W9SGDNQA2C  B00G9BNLQE      640460561   \n",
       "\n",
       "                                       product_title     product_category  \\\n",
       "0              Madden NFL 16 - Xbox One Digital Code  Digital_Video_Games   \n",
       "1                                Xbox Live Gift Card  Digital_Video_Games   \n",
       "2  Command & Conquer The Ultimate Collection [Ins...  Digital_Video_Games   \n",
       "3                      Playstation Plus Subscription  Digital_Video_Games   \n",
       "4  Saints Row IV - Enter The Dominatrix [Online G...  Digital_Video_Games   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes  vine  verified_purchase  \\\n",
       "0            2              2            3     0                  0   \n",
       "1            5              0            0     0                  1   \n",
       "2            5              0            0     0                  1   \n",
       "3            5              0            0     0                  1   \n",
       "4            5              0            0     0                  1   \n",
       "\n",
       "                        review_headline  \\\n",
       "0  A slight improvement from last year.   \n",
       "1                            Five Stars   \n",
       "2               Hail to the great Yuri!   \n",
       "3                            Five Stars   \n",
       "4                            Five Stars   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0  I keep buying madden every year hoping they ge...  2015-08-31  \n",
       "1                                            Awesome  2015-08-31  \n",
       "2  If you are prepping for the end of the world t...  2015-08-31  \n",
       "3                                            Perfect  2015-08-31  \n",
       "4                                           Awesome!  2015-08-31  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_df = pd.DataFrame.from_dict(dataset['train'])\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fc8099d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6fc8099d",
    "outputId": "96c5d398-4799-4d60-a26d-a294790964bd",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24970"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_reviews = data_df.loc[data_df[\"star_rating\"] == 1]\n",
    "len(bad_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f39fabf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5f39fabf",
    "outputId": "e8efa180-6bbe-46f2-efa4-f5538a405b84",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    As has been written by so many others, I quick...\n",
       "14                Lames purchase I almost never made...\n",
       "24                                               Gross!\n",
       "26           Not the best graphics :(<br />Dissapointed\n",
       "30                                               Stolen\n",
       "Name: review_body, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_reviews[\"review_body\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "FILluNOqEwoq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FILluNOqEwoq",
    "outputId": "ccd0d349-752e-4543-e9a1-87b4d5ab146f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y0/_r4pmpsx6qjbvc93xxxb0lbm0000gn/T/ipykernel_49208/1791466554.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  bad_reviews[\"message_len\"]=[len(i) for i in bad_reviews[\"review_body\"].values] # [0 for i in range(0,24970)]\n"
     ]
    }
   ],
   "source": [
    "bad_reviews[\"message_len\"]=[len(i) for i in bad_reviews[\"review_body\"].values] # [0 for i in range(0,24970)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18el3mHKFe0K",
   "metadata": {
    "id": "18el3mHKFe0K"
   },
   "outputs": [],
   "source": [
    "# dall=dall.mul(row.loc[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ArJhSLHFlso",
   "metadata": {
    "id": "2ArJhSLHFlso"
   },
   "outputs": [],
   "source": [
    "# [len(i) for i in bad_reviews[\"review_body\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "_sodZQxEF-Q6",
   "metadata": {
    "id": "_sodZQxEF-Q6"
   },
   "outputs": [],
   "source": [
    "bad_reviews_small=bad_reviews.loc[bad_reviews[\"message_len\"]<128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "PVwRVkbDG3er",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVwRVkbDG3er",
    "outputId": "a1eeb38c-82f5-449e-e4f4-fe2647181091"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7671, 16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_reviews_small.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vGgvT7LoG86J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vGgvT7LoG86J",
    "outputId": "acb479ee-1c21-4bcb-fdf4-49e67f7baeb0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24970, 16)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3YOg9zjBGqO1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3YOg9zjBGqO1",
    "outputId": "d5949cc6-d926-4dff-f839-fb62d91b5912"
   },
   "outputs": [],
   "source": [
    "# bad_reviews[\"message_len\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bhFkz3zRHAwk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bhFkz3zRHAwk",
    "outputId": "f1780f6e-102f-4240-ba71-a19f9f7a17ab"
   },
   "outputs": [],
   "source": [
    "# bad_reviews[\"message_len\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511a2a04",
   "metadata": {
    "id": "511a2a04"
   },
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcb23efd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcb23efd",
    "outputId": "08e0a687-6d45-4077-cdf7-be05c2d23308",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n"
     ]
    }
   ],
   "source": [
    "# a little sentiment analysis\n",
    "model_name = \"finiteautomata/bertweet-base-sentiment-analysis\"\n",
    "sentiment_pipeline = pipeline(\"text-classification\", model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accac968",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "accac968",
    "outputId": "754198c7-f223-4b3a-d07c-bddeefb61159",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'text-classification',\n",
       " 'model': RobertaForSequenceClassification(\n",
       "   (roberta): RobertaModel(\n",
       "     (embeddings): RobertaEmbeddings(\n",
       "       (word_embeddings): Embedding(64001, 768, padding_idx=1)\n",
       "       (position_embeddings): Embedding(130, 768, padding_idx=1)\n",
       "       (token_type_embeddings): Embedding(1, 768)\n",
       "       (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "     (encoder): RobertaEncoder(\n",
       "       (layer): ModuleList(\n",
       "         (0): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (1): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (2): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (3): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (4): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (5): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (6): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (7): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (8): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (9): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (10): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "         (11): RobertaLayer(\n",
       "           (attention): RobertaAttention(\n",
       "             (self): RobertaSelfAttention(\n",
       "               (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "             (output): RobertaSelfOutput(\n",
       "               (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "               (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "               (dropout): Dropout(p=0.1, inplace=False)\n",
       "             )\n",
       "           )\n",
       "           (intermediate): RobertaIntermediate(\n",
       "             (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (intermediate_act_fn): GELUActivation()\n",
       "           )\n",
       "           (output): RobertaOutput(\n",
       "             (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "             (dropout): Dropout(p=0.1, inplace=False)\n",
       "           )\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (classifier): RobertaClassificationHead(\n",
       "     (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (dropout): Dropout(p=0.1, inplace=False)\n",
       "     (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "   )\n",
       " ),\n",
       " 'tokenizer': BertweetTokenizer(name_or_path='finiteautomata/bertweet-base-sentiment-analysis', vocab_size=64000, model_max_length=128, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}),\n",
       " 'feature_extractor': None,\n",
       " 'modelcard': None,\n",
       " 'framework': 'pt',\n",
       " 'device': device(type='cpu'),\n",
       " 'torch_dtype': None,\n",
       " 'binary_output': False,\n",
       " 'call_count': 0,\n",
       " '_batch_size': None,\n",
       " '_num_workers': None,\n",
       " '_preprocess_params': {},\n",
       " '_forward_params': {},\n",
       " '_postprocess_params': {}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bae1fda5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bae1fda5",
    "outputId": "7e2b4a6f-9670-4709-ef6c-026546e5012e",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEG', 'score': 0.9216219782829285}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = bad_reviews_small[\"review_body\"].values[0]\n",
    "sentiment_pipeline(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12759d93",
   "metadata": {
    "id": "12759d93",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaner_data = None\n",
    "\n",
    "for index, bad_review in bad_reviews_small.iterrows():\n",
    "    sentiment = sentiment_pipeline(bad_review[\"review_body\"])[0]\n",
    "    if (sentiment[\"label\"] == \"POSITIVE\"):\n",
    "        cleaner_data = bad_reviews.drop(index=index, axis = 0)\n",
    "    elif sentiment[\"score\"] < 0.8:\n",
    "        cleaner_data = bad_reviews.drop(index=index, axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae305d0c",
   "metadata": {
    "id": "ae305d0c",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24969"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaner_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82737349",
   "metadata": {
    "id": "82737349",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaner_data.to_csv(\"cleaner_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4e28aa",
   "metadata": {
    "id": "fa4e28aa"
   },
   "source": [
    "# Retraining on top of transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f133eaaf",
   "metadata": {
    "id": "d865ebeb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de42b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = pd.read_csv(\"cleaner_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43b5bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(cleaned_data.review_body, test_size = 0.15)\n",
    "train.to_csv(\"train.csv\")\n",
    "test.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4cfab848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17838    You cant bully your paying customers EA!  You ...\n",
       "6974     Do not download. You will need &#34;steam&#34;...\n",
       "235      I bought this with out reading the other revie...\n",
       "17348    This is yet another example why EA should not ...\n",
       "13511    The game is installable on Windows 7, however,...\n",
       "Name: review_body, dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed8b8786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "328d3cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ameezingwongstein/Library/Python/3.9/lib/python/site-packages/transformers/data/datasets/language_modeling.py:54: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "Creating features from dataset file at \n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1915948 > 1024). Running this sequence through the model will result in indexing errors\n",
      "Saving features into cached file cached_lm_GPT2TokenizerFast_128_train.csv [took 0.056 s]\n",
      "Creating features from dataset file at \n",
      "Saving features into cached file cached_lm_GPT2TokenizerFast_128_test.csv [took 0.016 s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
    "\n",
    "def load_dataset(train_path,test_path,tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128)\n",
    "     \n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)   \n",
    "    \n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset,test_dataset,data_collator\n",
    "\n",
    "train_dataset,test_dataset,data_collator = load_dataset(\"train.csv\",'test.csv',tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840baf54",
   "metadata": {
    "id": "840baf54",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 14968\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1404\n",
      "  Number of trainable parameters = 124439808\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='416' max='1404' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 416/1404 2:11:04 < 5:12:48, 0.05 it/s, Epoch 0.89/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \n",
    "from transformers import Trainer, TrainingArguments\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./logs\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=3, # number of training epochs\n",
    "    per_device_train_batch_size=32, # batch size for training\n",
    "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
    "    eval_steps = 400, # Number of update steps between two evaluations.\n",
    "    save_steps=800, # after # steps model is saved \n",
    "    warmup_steps=500,# number of warmup steps for learning rate scheduler\n",
    "    prediction_loss_only=True,\n",
    "    )\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175d14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e4151c6cff940f1aef9ed8362f2af58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2bea7f63b6f64633a4c93881d01a5994": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ff1031bdd444992845b2cb6a5ce3e5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_df84ee6dc21d46d3a220542696f65cf0",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_41146de71b99490585176f82c5b8aa0d",
      "value": 1
     }
    },
    "41146de71b99490585176f82c5b8aa0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6711d62b4f884571b95ea748c17a3298": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edb6369fa1464d79805c380fc4fbf768",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_0e4151c6cff940f1aef9ed8362f2af58",
      "value": " 1/1 [00:00&lt;00:00, 26.20it/s]"
     }
    },
    "7eac96a60f474b38b3958a755072e33a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d265e94caea24d5a98f9611881e0cd93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc11f13f935248ddb2c658747e2714bf",
       "IPY_MODEL_2ff1031bdd444992845b2cb6a5ce3e5f",
       "IPY_MODEL_6711d62b4f884571b95ea748c17a3298"
      ],
      "layout": "IPY_MODEL_7eac96a60f474b38b3958a755072e33a"
     }
    },
    "df84ee6dc21d46d3a220542696f65cf0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edb6369fa1464d79805c380fc4fbf768": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee7ed57907b34da88f27f0370d325ce4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc11f13f935248ddb2c658747e2714bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2bea7f63b6f64633a4c93881d01a5994",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ee7ed57907b34da88f27f0370d325ce4",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
